{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Clustering Algorithms</h1>\n",
    "<h3>Unsupervised learning</h3>\n",
    "In unsupervised learning, we do something slightly different.\n",
    "We say, all right, here's our space of independent variables.\n",
    "Now try and see the many features that we have.\n",
    "And now try and see what values of these features\n",
    "will make subsets of these cases closer together\n",
    "by some estimate.\n",
    "OK, how do they fit closer together?\n",
    "<ul>\n",
    "<li>The algorithm tries to group similar data together (clusters) using the values of the feature space.</li>\n",
    "\n",
    "You can think of having a vast--\n",
    "data points sitting all over the place.\n",
    "And you want to find planes that cut through the space, that can\n",
    "group these data points together in a similar way.\n",
    "OK, they're called clusters.\n",
    "And they use only value the feature space.\n",
    "Of course, what we do is we, again,\n",
    "work our way through a training and testing sample.\n",
    "And in the training sample, we give it\n",
    "the independent variables, and it groups them.\n",
    "And then we want to measure how well that's\n",
    "done by looking whether these groups map\n",
    "onto something in the real world that makes sense to us, right.\n",
    "So, for example, we could take physical characteristics\n",
    "of people and say, can we differentiate\n",
    "between these physical characteristics\n",
    "and put them into two groups?\n",
    "If we put them into two groups, maybe we\n",
    "can figure out men versus women, something like that.\n",
    "But we don't say that this case corresponds\n",
    "to a man or this set of features corresponds to women.\n",
    "We let the algorithm use the features to differentiate\n",
    "between the two groups of people.\n",
    "</ul>\n",
    "<h3>K-Means Clusterng</h3>\n",
    "\n",
    "A popular algorithm for doing clustering\n",
    "is __K-means clustering__, what it does\n",
    "is it partitions the dataspace into clusters.\n",
    "And it minimizes the distance between the mean of a cluster\n",
    "and the data points.\n",
    "\n",
    "So every data point is sitting in n-dimensional space, where\n",
    "__each dimension is a feature__.\n",
    "And so you can measure the distance between one data\n",
    "point and another data point.\n",
    "And we want to find clusters where\n",
    "the __mean distance between data points in each cluster\n",
    "is minimal__.\n",
    "\n",
    "So we want to minimize that distance.\n",
    "And what you need to know in advance\n",
    "is how many clusters you're going to have in your data\n",
    "set, in your domain, right.\n",
    "Like, if you're doing men versus women, you have two clusters.\n",
    "You know that.\n",
    "Tou can't say _find me the number of clusters in that case_.\n",
    "You need to actually tell the K-means algorithm\n",
    "how many clusters to use.\n",
    "\n",
    "<ul>\n",
    "<li>partitions the dataspace into clusters\n",
    "<li>minimizes distance between the mean of a cluster and the data points\n",
    "<li>the desired number of clusters must be known in advance\n",
    "</ul>\n",
    "\n",
    "<h2>Image recognition dataset</h2>\n",
    "<ul>\n",
    "<li>Digits 0-9 pixelated into 64 quadrants\n",
    "<li>Each value represents the area that is shaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': \"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\",\n",
       " 'data': array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "        [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "        [  0.,   0.,  10., ...,  12.,   1.,   0.]]),\n",
       " 'images': array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
       "         [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
       "         [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
       "         ..., \n",
       "         [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
       "         [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
       "         [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
       " \n",
       "        [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
       "         [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
       "         ..., \n",
       "         [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "         [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
       " \n",
       "        [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
       "         [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
       "         [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
       "         ..., \n",
       "         [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
       "         [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
       "         [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
       " \n",
       "        ..., \n",
       "        [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
       "         [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
       "         [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
       "         ..., \n",
       "         [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
       "         [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
       "         [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
       " \n",
       "        [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
       "         [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
       "         ..., \n",
       "         [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
       "         [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
       "         [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
       " \n",
       "        [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
       "         [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
       "         [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
       "         ..., \n",
       "         [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
       "         [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
       "         [  0.,   1.,   8., ...,  12.,   1.,   0.]]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data to normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
       "         1.6951369 , -0.19600752],\n",
       "       ..., \n",
       "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
       "        -0.26113572, -0.19600752]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scale(digits.data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the digit images and their associated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n",
       "       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n",
       "       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n",
       "       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n",
       "       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n",
       "       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n",
       "       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "target\n",
      "target_names\n",
      "images\n",
      "DESCR\n"
     ]
    }
   ],
   "source": [
    "for item in digits:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.,   0.,   0.,  13.,\n",
       "        15.,  10.,  15.,   5.,   0.,   0.,   3.,  15.,   2.,   0.,  11.,\n",
       "         8.,   0.,   0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.,   0.,\n",
       "         5.,   8.,   0.,   0.,   9.,   8.,   0.,   0.,   4.,  11.,   0.,\n",
       "         1.,  12.,   7.,   0.,   0.,   2.,  14.,   5.,  10.,  12.,   0.,\n",
       "         0.,   0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAABiCAYAAAAssbghAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlHisDImIKPFYGRIRUeKxMiQiosT7f/ur/KuJ0xgGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x161b6505828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_digits(images,y,max_n=10):\n",
    "    # set up the figure size in inches\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1,hspace=.05, wspace=.5)\n",
    "    i = 0\n",
    "    while i < max_n and i < digits.images.shape[0]:\n",
    "        # plot the images in a matrix of 20x20\n",
    "        p = fig.add_subplot(10, 10, i + 1, xticks=[],yticks=[])\n",
    "        p.imshow(images[i], cmap=plt.cm.bone) # in black-white \n",
    "        # label the image with the target value\n",
    "        p.text(3, 14, str(y[i]))\n",
    "        i = i + 1\n",
    "print_digits(digits.images, digits.target, max_n=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test,images_train,images_test = train_test_split(\n",
    "    data,digits.target,digits.images,test_size=0.25,random_state=42)\n",
    "\n",
    "n_samples,n_features = X_train.shape\n",
    "n_digits = len(np.unique(y_train))\n",
    "labels = y_train\n",
    "\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model and fit the data\n",
    "\n",
    "And the last thing we do, which we do always\n",
    "is always the same thing, is we import the cluster algorithm--\n",
    "the cluster library, a module, and create a k-means clustering\n",
    "algorithm from that.\n",
    "\n",
    "We tell it to initialize it by doing some initialization\n",
    "stuff.\n",
    "So what it-- k-means works better when you initialize it,\n",
    "so we initialize it initially.\n",
    "We run this pre-algorithm, you can think of,\n",
    "to do the initialization.\n",
    "And to start with a-- well, what k-means does\n",
    "is it starts by randomly allocating the digits, right?\n",
    "So it'll say, all right, I need 10 categories,\n",
    "and that's the number of clusters, 10.\n",
    "And it'll randomly assign the data to 10 categories.\n",
    "But if you can sort of intelligently\n",
    "start off and use some knowledge about the data,\n",
    "like maybe the means inside the values, all that kind of stuff,\n",
    "then you're better off.\n",
    "So you can use this k-means plus plus to actually start off\n",
    "the--\n",
    "start the algorithm at a better point.\n",
    "And so that's the k-means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "clf = cluster.KMeans(init='k-means++',n_clusters=10,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-means++ runs an initializer before using the k-means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.,   0.,   2., ...,  16.,  11.,   0.],\n",
       "        [  0.,   0.,   8., ...,   3.,   0.,   0.],\n",
       "        [  0.,   0.,  13., ...,   0.,   0.,   0.],\n",
       "        ..., \n",
       "        [  0.,   6.,  16., ...,  16.,   5.,   0.],\n",
       "        [  0.,   0.,   3., ...,   8.,   0.,   0.],\n",
       "        [  0.,   0.,   4., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   5.,  16., ...,   0.,   0.,   0.],\n",
       "        [  0.,  11.,  14., ...,   0.,   0.,   0.],\n",
       "        [  0.,   8.,  11., ...,   0.,   0.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,   0., ...,   5.,   1.,   0.],\n",
       "        [  0.,   1.,  11., ...,  16.,  10.,   0.],\n",
       "        [  0.,   5.,  16., ...,   6.,   1.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   4., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,  13., ...,   7.,   0.,   0.],\n",
       "        [  0.,   3.,  16., ...,  15.,   6.,   0.],\n",
       "        ..., \n",
       "        [  0.,   4.,  12., ...,  11.,   6.,   0.],\n",
       "        [  0.,   0.,  14., ...,  14.,   1.,   0.],\n",
       "        [  0.,   0.,   7., ...,   2.,   0.,   0.]],\n",
       "\n",
       "       ..., \n",
       "       [[  0.,   0.,   9., ...,  13.,   1.,   0.],\n",
       "        [  0.,   0.,  12., ...,  16.,   7.,   0.],\n",
       "        [  0.,   0.,   0., ...,  16.,   4.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,   7., ...,   0.,   0.,   0.],\n",
       "        [  0.,   2.,  15., ...,   7.,   0.,   0.],\n",
       "        [  0.,   0.,   9., ...,  16.,   2.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   1., ...,  10.,   0.,   0.],\n",
       "        [  0.,   0.,   8., ...,  14.,   0.,   0.],\n",
       "        [  0.,   1.,  15., ...,  15.,   0.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,   4., ...,   9.,   1.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   1., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
       "        [  0.,   0.,   1., ...,   4.,   0.,   0.],\n",
       "        [  0.,   0.,   3., ...,   2.,   0.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,  14., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   9., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   2., ...,   1.,   0.,   0.]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call print_digits with training images, and computed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
